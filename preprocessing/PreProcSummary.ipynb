{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a summary of preprocessing steps that were taken. This will provide you with individual files that are ready for serialization. All gene IDs are sorted such that the lower ID and its corresponding symbol will appear before that with the higher ID. This ensures any duplicated can be easily filtered later."
      ],
      "metadata": {
        "id": "vH50BmLkjsYV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j76DN7aKR4zc"
      },
      "outputs": [],
      "source": [
        "# used pandas\n",
        "import pandas as pd\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BioGRID"
      ],
      "metadata": {
        "id": "ikyYcNpAR-G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read it in\n",
        "# can be found here https://downloads.thebiogrid.org/File/BioGRID/Release-Archive/BIOGRID-4.4.224/BIOGRID-ALL-4.4.224.tab3.zip\n",
        "df = pd.read_csv('biogrid path',sep = \"\\t\", low_memory=False)"
      ],
      "metadata": {
        "id": "ToG8qEAWR_bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove unneded meta data\n",
        "toDrop = [\"#BioGRID Interaction ID\",\n",
        "       'BioGRID ID Interactor A', 'BioGRID ID Interactor B',\n",
        "       'Systematic Name Interactor A', 'Systematic Name Interactor B',\n",
        "       'Synonyms Interactor A', 'Synonyms Interactor B',\n",
        "       'Organism ID Interactor A', 'Organism ID Interactor B',\n",
        "       'SWISS-PROT Accessions Interactor A', 'TREMBL Accessions Interactor A',\n",
        "       'REFSEQ Accessions Interactor A', 'SWISS-PROT Accessions Interactor B',\n",
        "       'TREMBL Accessions Interactor B', 'REFSEQ Accessions Interactor B',\n",
        "       'Ontology Term IDs', 'Ontology Term Names', 'Ontology Term Categories',\n",
        "       'Ontology Term Qualifier IDs', 'Ontology Term Qualifier Names',\n",
        "       'Ontology Term Types', 'Organism Name Interactor A',\n",
        "       'Organism Name Interactor B','Score', 'Modification', 'Qualifications', 'Tags']\n",
        "\n",
        "df = df.drop(columns=toDrop)\n"
      ],
      "metadata": {
        "id": "QJLwp_3KSJ9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get rid of pubmed prefix on IDs\n",
        "for index in df.index:\n",
        "  df.loc[index, \"Publication Source\"] = df.loc[index, \"Publication Source\"][7::]"
      ],
      "metadata": {
        "id": "rXsykmj5Slb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep only PPIs and not protien-gene interactions\n",
        "df = df.loc[df[\"Experimental System Type\"].str.contains('physical')]"
      ],
      "metadata": {
        "id": "9HZaHHbFaRqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove self-reactions\n",
        "df = df[df['Entrez Gene Interactor A'] != df['Entrez Gene Interactor B']]"
      ],
      "metadata": {
        "id": "GOOjSQ17ZjM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dtype to string\n",
        "df.applymap(str)"
      ],
      "metadata": {
        "id": "oojP2noMb8-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort columns so lower comes first\n",
        "\n",
        "for index in df:\n",
        "  idA = df.loc[index, \"Entrez Gene Interactor A\tEntrez Gene\"]\n",
        "  idB = df.loc[index, \"Entrez Gene Interactor B\tEntrez Gene\"]\n",
        "  symbolA = df.loc[index, \"Official Symbol Interactor A\"]\n",
        "  symbolB = df.loc[index, \"Official Symbol Interactor B\"]\n",
        "\n",
        "  if idA > idB:\n",
        "    # swap both columns\n",
        "    df.loc[index, \"Entrez Gene Interactor A\tEntrez Gene\"] = idB\n",
        "    df.loc[index, \"Entrez Gene Interactor B\tEntrez Gene\"] = idA\n",
        "    df.loc[index, \"Official Symbol Interactor A\"] = symbolB\n",
        "    df.loc[index, \"Official Symbol Interactor B\"] = symbolA\n"
      ],
      "metadata": {
        "id": "3ZSj_bBWkPa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"biogrid_ready_for_serializing.csv\")"
      ],
      "metadata": {
        "id": "Mazx4g-_S9RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BioPlex3.0"
      ],
      "metadata": {
        "id": "gU7WI6v0TM5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# link to source https://bioplex.hms.harvard.edu/interactions.php\n",
        "df2 = pd.read_csv(\"path to file\", sep = '\\t')"
      ],
      "metadata": {
        "id": "52UE8CwiTOj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pW: probability of a wrong ID\n",
        "#pNI: probability of a non-interactor (non-specific background)\n",
        "#pInt: probability of an interactor\n",
        "# can drop other data if needed\n",
        "\n",
        "# note from Dr. Huttlin on the paper: \"Though the algorithm returns \"probabilities\", I wouldn't take them too literally in that sense. They're best interpreted as numerical scores with pInt reflecting our confidence that a particular protein is a true interacting protein.\"\n",
        "\n",
        "toDrop = ['UniprotA', 'UniprotB']\n",
        "df2 = df2.drop(columns=toDrop)"
      ],
      "metadata": {
        "id": "bwxhy10tTdG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add experimental system name\n",
        "df2['Experimental System'] = ['Affinity-Purification Mass Spectrometry']* len(df2)"
      ],
      "metadata": {
        "id": "h-zic4lRZCl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map data to string\n",
        "df2.applymap(str)"
      ],
      "metadata": {
        "id": "IevKnpvKZG2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename columns\n",
        "df2 = df2.rename(columns = {\"pInt\": \"Interaction Confidence\"})"
      ],
      "metadata": {
        "id": "7QxSrPx_ZLhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove self interactions - do not think is necessary\n",
        "df2 = df2[df2['GeneA'] != df2['GeneB']]"
      ],
      "metadata": {
        "id": "UU7YuNNKecz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort columns so lower comes first\n",
        "\n",
        "for index in df2:\n",
        "  idA = df2.loc[index, \"GeneA\"]\n",
        "  idB = df2.loc[index, \"GeneB\"]\n",
        "  symbolA = df2.loc[index, \"SymbolA\"]\n",
        "  symbolB = df2.loc[index, \"SymbolB\"]\n",
        "\n",
        "  if idA > idB:\n",
        "    # swap both columns\n",
        "    df2.loc[index, \"GeneA\"] = idB\n",
        "    df2.loc[index, \"GeneB\"] = idA\n",
        "    df2.loc[index, \"SymbolA\"] = symbolB\n",
        "    df2.loc[index, \"SymbolB\"] = symbolA"
      ],
      "metadata": {
        "id": "owobINgflnRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv(\"bioplex_ready_for_serializing.csv\", index = False)"
      ],
      "metadata": {
        "id": "GU3lDnvhZQtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IID"
      ],
      "metadata": {
        "id": "UvZczo4mZX1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# link to source http://iid.ophid.utoronto.ca/\n",
        "df3 = pd.read_csv(\"put iid path in\", sep = \"\\t\")"
      ],
      "metadata": {
        "id": "njwpnfiHbQYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so much meta data - can be explored later - copy over only the esentials\n",
        "df3 = df3[['symbol1', 'symbol2', 'methods', 'pmids', 'db_with_ppi', 'evidence_type']].copy()"
      ],
      "metadata": {
        "id": "4YTDkEj-bdLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename rows\n",
        "df3 =df3.rename(columns = {'methods': 'Experimental System', 'db_with_ppi':'Source Database'})"
      ],
      "metadata": {
        "id": "Vk2hk_mXbxZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some proteins are not from IID acording to source_database, because IID is an aggregator for simplicity, can add IID to sourceDB, regex filtering is used in neo4j implementation\n",
        "for index in df3.index:\n",
        "  if bool(re.search( '.*iid.*', re.containsdf3.loc[index,'source_database'])):\n",
        "    df3.loc[index,'source_database'] =  df3.loc[index,'source_database'] + \"|iid\""
      ],
      "metadata": {
        "id": "V52z3sCkcd6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove self interactions - do not think is necessary\n",
        "df3 = df3[df3['symbol1'] != df3['symbol2']]"
      ],
      "metadata": {
        "id": "M7Gf36wIeYwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map to entrez gene ID - used PyPath\n",
        "# pip install https://github.com/saezlab/pypath.git\n",
        "from pypath.utils import mapping\n",
        "\n",
        "# make empty columns\n",
        "\n",
        "df3['entrez1'] = None\n",
        "df3['entrez2'] = None\n",
        "\n",
        "for index in df3:\n",
        "  a = df3.loc[index, 'symbolA']\n",
        "  b = df3.loc[index, 'symbolB']\n",
        "  df3.loc[index,'entrez 1'] = mapping.map_name(a, 'genesymbol', 'entrez')\n",
        "  df3.loc[index,'entrez 2'] = mapping.map_name(b, 'genesymbol', 'entrez')\n",
        "\n",
        "# data will be stored inside dicts on length = 1 so must remove from set\n",
        "\n",
        "# convert dtype to string\n",
        "df3.applymap(str)\n",
        "\n",
        "# remove gene id from set\n",
        "for index in df3.index:\n",
        "  res = \"\"\n",
        "  # length of set is one\n",
        "  for s in df3.loc[index, 'entrez 1']:\n",
        "    res = res + str(s)\n",
        "\n",
        "  df3.loc[index, 'entrez 1'] = res\n",
        "\n",
        "  res2 = \"\"\n",
        "  for i in df3.loc[index, 'uniprot2']:\n",
        "    res2 = res2 + str(i)\n",
        "\n",
        "  df3.loc[index, 'entrez 2'] = res2\n",
        "\n"
      ],
      "metadata": {
        "id": "b561L4cnevNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort columns so lower comes first\n",
        "\n",
        "for index in df3:\n",
        "  idA = df3.loc[index, \"entrez 1\"]\n",
        "  idB = df3.loc[index, \"entrez 2\"]\n",
        "  symbolA = df3.loc[index, \"Symbol1\"]\n",
        "  symbolB = df3.loc[index, \"Symbol2\"]\n",
        "\n",
        "  if idA > idB:\n",
        "    # swap both columns\n",
        "    df3.loc[index, \"entrez 1\"] = idB\n",
        "    df3.loc[index, \"entrez 2\"] = idA\n",
        "    df3.loc[index, \"Symbol1\"] = symbolB\n",
        "    df3.loc[index, \"Symbol2\"] = symbolA"
      ],
      "metadata": {
        "id": "AH1wMjsbmGo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv(\"iid_ready_for_serializing.csv\", index = False)"
      ],
      "metadata": {
        "id": "cSVnb7N2ezaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "String"
      ],
      "metadata": {
        "id": "R0eC0DT3e9D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download for homo spaiens https://string-db.org/cgi/download?sessionId=bsWgk1f8vBeG\n",
        "\n",
        "df4 = pd.read_csv(\"path to file\", sep = ' ')\n"
      ],
      "metadata": {
        "id": "iZN486-qmcib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# string is so big so all the mapping will take alot of time, which is why every cell is so split up\n",
        "# make sure you have done confidence score filtering first\n",
        "\n",
        "# make new df with the combined score\n",
        "norm_df = df4['combined_score']\n",
        "\n",
        "# compute score\n",
        "norm_df = (norm_df-norm_df.min())/(norm_df.max()-norm_df.min())\n",
        "\n",
        "# make it a df and rename\n",
        "norm_df = norm_df.to_frame()\n",
        "norm_df = norm_df.rename(columns = {'combined_score': 'normalized_score'})\n",
        "\n",
        "# add back to original\n",
        "df4 = pd.concat([df4, norm_df], axis = 1)\n"
      ],
      "metadata": {
        "id": "nJ8U-_2Mp3KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find a confidence value threshhold - remember all reactions are double counted so divide number by 2\n",
        "# this cell does not save the data frame to memory, so you can play around with different scores before you commit\n",
        "x = 0.98\n",
        "df4.loc[df4['normalized_score'] > x]\n",
        "\n",
        "print(len(df4))"
      ],
      "metadata": {
        "id": "TlUGYfczq1t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ok this is for real now - make sure you haveq the right score\n",
        "x = 0.98\n",
        "df4 = df4.loc[df4['normalized_score'] > x]"
      ],
      "metadata": {
        "id": "Gy0Ly1VSrCaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map to entrez IDs link to string mapper https://string-db.org/mapping_files/entrez/\n",
        "\n",
        "procDF = pd.read_csv(\"path to mapper file\")\n",
        "\n",
        "# build mapper\n",
        "mapper = {}\n",
        "for index in procDF.index:\n",
        "  mapper[procDF.loc[index, 'STRING']] = procDF.loc[index, 'entrez']\n"
      ],
      "metadata": {
        "id": "Zl6iKGy8nkfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map to entrez ids- if entrez id not there set to negatvie one too filter out\n",
        "for index in df4.index:\n",
        "  x = df4.loc[index,'protein1']\n",
        "  if x in mapper:\n",
        "    df4.loc[index,'protein1'] = mapper[x]\n",
        "  else:\n",
        "    df4.loc[index,'protein1'] = '-1'\n",
        "  y = df4.loc[index,'protein2']\n",
        "  if y in mapper:\n",
        "    df4.loc[index,'protein2'] = mapper[y]\n",
        "  else:\n",
        "    df4.loc[index,'protein2'] = '-1'"
      ],
      "metadata": {
        "id": "wRYWVvyooThh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop columns without entrez IDs\n",
        "df4 = df4.loc[(df4['protein1'] != '-1') & (df4['protein1'] != '-1')]"
      ],
      "metadata": {
        "id": "Uf30ouuGooKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map to entrez gene ID - used PyPath\n",
        "# pip install https://github.com/saezlab/pypath.git\n",
        "from pypath.utils import mapping\n",
        "\n",
        "# make empty columns\n",
        "\n",
        "df4['entrez1'] = None\n",
        "df4['entrez2'] = None\n",
        "\n",
        "for index in df3:\n",
        "  a = df4.loc[index, 'protein1']\n",
        "  b = d4f.loc[index, 'protein2']\n",
        "  df4.loc[index,'entrez 1'] = mapping.map_name(a, 'genesymbol', 'entrez')\n",
        "  df4.loc[index,'entrez 2'] = mapping.map_name(b, 'genesymbol', 'entrez')\n",
        "\n",
        "# data will be stored inside dicts on length = 1 so must remove from set\n",
        "\n",
        "# convert dtype to string\n",
        "df4.applymap(str)\n",
        "\n",
        "# remove gene id from set\n",
        "for index in df4.index:\n",
        "  res = \"\"\n",
        "  # length of set is one\n",
        "  for s in df4.loc[index, 'entrez 1']:\n",
        "    res = res + str(s)\n",
        "\n",
        "  df4.loc[index, 'entrez 1'] = res\n",
        "\n",
        "  res2 = \"\"\n",
        "  for i in df4.loc[index, 'uniprot2']:\n",
        "    res2 = res2 + str(i)\n",
        "\n",
        "  df4.loc[index, 'entrez 2'] = res2\n"
      ],
      "metadata": {
        "id": "zqpGPJUdowCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove self interactions - do not think is necessary\n",
        "df4 = df4[df4['protein1'] != df4['protein2']]"
      ],
      "metadata": {
        "id": "kjfgTpsqpJkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort columns so lower comes first\n",
        "\n",
        "for index in df4:\n",
        "  idA = df4.loc[index, \"entrez 1\"]\n",
        "  idB = df4.loc[index, \"entrez 2\"]\n",
        "  symbolA = df4.loc[index, \"protein1\"]\n",
        "  symbolB = df4.loc[index, \"protein2\"]\n",
        "\n",
        "  if idA > idB:\n",
        "    # swap both columns\n",
        "    df4.loc[index, \"entrez 1\"] = idB\n",
        "    df4.loc[index, \"entrez 2\"] = idA\n",
        "    df4.loc[index, \"protein1\"] = symbolB\n",
        "    df4.loc[index, \"protein2\"] = symbolA"
      ],
      "metadata": {
        "id": "LukUWVbNpPWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# string double counts reacitons, make sure to run this line after sorting\n",
        "df4 = df4.drop_duplicates(subset = [\"entrez 1\", \"entrez 2\"])"
      ],
      "metadata": {
        "id": "lGliI-WcpiEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.to_csv(\"string_ready_for_serializing.csv\", index = False)"
      ],
      "metadata": {
        "id": "SWJCHPwyrMPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}